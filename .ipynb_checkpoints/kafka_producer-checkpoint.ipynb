{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck_bL1UGGE8K",
        "outputId": "d99e9069-218a-46e5-a8f9-e185d8f3873e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kafka-python\n",
            "  Downloading kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/246.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/246.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.5/246.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install kafka-python\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from kafka import KafkaProducer\n",
        "from time import sleep\n",
        "from json import dumps\n",
        "import json"
      ],
      "metadata": {
        "id": "MyIUOjxoGXJs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "producer = KafkaProducer(bootstrap_servers=['100.26.234.201:9092'], #change ip here\n",
        "                         value_serializer=lambda x:\n",
        "                         dumps(x).encode('utf-8'))"
      ],
      "metadata": {
        "id": "IFF_l0bbGaf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "producer.send('demo_testing2', value={'surnasdasdame':'parasdasdmar'})\n"
      ],
      "metadata": {
        "id": "aZ1AeobPGfOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/darshilparmar/stock-market-kafka-data-engineering-project/blob/main/indexProcessed.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH3E7gp7GfUN",
        "outputId": "7e8aaef6-54b6-4f72-8a70-55451b5f8a82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-18 19:23:52--  https://github.com/darshilparmar/stock-market-kafka-data-engineering-project/blob/main/indexProcessed.csv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4893 (4.8K) [text/plain]\n",
            "Saving to: ‘indexProcessed.csv’\n",
            "\n",
            "\rindexProcessed.csv    0%[                    ]       0  --.-KB/s               \rindexProcessed.csv  100%[===================>]   4.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-08-18 19:23:52 (53.3 MB/s) - ‘indexProcessed.csv’ saved [4893/4893]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/indexProcessed.csv\")\n"
      ],
      "metadata": {
        "id": "cgJ2KdrZGfYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    dict_stock = df.sample(1).to_dict(orient=\"records\")[0]\n",
        "    producer.send('demo_test', value=dict_stock)\n",
        "    sleep(1)"
      ],
      "metadata": {
        "id": "xy5eGKU4HFbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "producer.flush() #clear data from kafka server\n"
      ],
      "metadata": {
        "id": "hpRywOQvHFf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}